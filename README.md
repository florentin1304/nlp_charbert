# Sentence Embedding Project: CharBERT
CharBERT Extensions for Deep Natural Language Processing course. Group work by [Luca Catalano](https://github.com/LucaCatalano13), [Giacomo Rosso](https://github.com/jackyjack00), [Claudio Savelli](https://github.com/ClaudioSavelli) and [Florentin-Cristian Udrea](https://github.com/florentin1304).

To download the datasets, simply run the three Bash commands in the datasets/model. These will download the datasets and unpack them in the right folder. 

To run the code, you need to install the libraries in the requirements.txt file. To do this, simply run the command `pip install -r requirements.txt`.

To run the code, you need to download the pre-trained models and put them in the right folder. The models can be downloaded from [here](https://drive.google.com/drive/folders/1FPf9s0rLA-9XSM0iMe7_Es2zjT3trkeq?hl=it). The models must be placed in the `models` folder in the project's main folder.

Within the project, there is a jupyter notebook for each of the main sections of the project. These notebooks are:
- `run_baseline.ipynb` where the proposed paper is replicated. 
- `run_multilingual.ipynb` where the multilingual extension is run.
- `run_domain_shift.ipynb` where the medical domain shift extension is done.