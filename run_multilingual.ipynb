{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   CharBERT Multilingual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /datasets/load_wiki_resized.py\n",
    "!python datasets/load_conll2003.py\n",
    "!python3 /datasets/load_conll2003_ita.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BertCheckpoint: bert-base-multilingual-cased\n",
    "\n",
    "Dataset: Wikil_eng + wiki_ita (resized)\n",
    "\n",
    "Output Dir: \"/model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./CharBERT/run_lm_finetuning.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_data_file \"./datasets/wikipedia_resized/wikil_eng_wiki_ita_train.txt\" \\\n",
    "    --eval_data_file  \"./datasets/wikipedia_resized/wikil_eng_wiki_ita_val.txt\" \\\n",
    "    --term_vocab \"./CharBERT/data/dict/term_vocab\" \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --char_vocab \"./CharBERT/data/dict/bert_char_vocab\" \\\n",
    "    --mlm_probability 0.10 \\\n",
    "    --input_nraws 1000 \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --per_gpu_eval_batch_size 4 \\\n",
    "    --save_steps 10000 \\\n",
    "    --block_size 384 \\\n",
    "    --mlm \\\n",
    "    --overwrite_output_dir \\\n",
    "    --output_dir  \"/model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run NER ENG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Model: \"/model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\"\n",
    "\n",
    "\n",
    "Dataset: conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ./CharBERT/run_ner.py \\\n",
    "                    --data_dir \"./datasets/CoNLL2003\" \\\n",
    "                    --model_type bert \\\n",
    "                    --model_name_or_path \"./model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "                    --output_dir  \"./model/output/multilingual/NER_cased/conll2003\" \\\n",
    "                    --num_train_epochs 3 \\\n",
    "                    --learning_rate 3e-5 \\\n",
    "                    --char_vocab \"./nlp_charbert/CharBERT/data/dict/bert_char_vocab\" \\\n",
    "                    --per_gpu_train_batch_size 6 \\\n",
    "                    --do_train \\\n",
    "                    --do_predict \\\n",
    "                    --overwrite_output_dir \\\n",
    "                    --save_steps 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run POS ENG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Model: \"/model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\"\n",
    "\n",
    "\n",
    "Dataset: conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python  ./CharBERT/run_pos.py \\\n",
    "                    --data_dir \"./datasets/CoNLL2003\" \\\n",
    "                    --model_type bert \\\n",
    "                    --model_name_or_path \"./model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "                    --output_dir \"./model/output/multilingual/POS_cased/conll2003\" \\\n",
    "                    --num_train_epochs 3 \\\n",
    "                    --char_vocab \"./CharBERT/data/dict/bert_char_vocab\" \\\n",
    "                    --learning_rate 2e-5 \\\n",
    "                    --per_gpu_train_batch_size 16 \\\n",
    "                    --per_gpu_eval_batch_size 16 \\\n",
    "                    --max_seq_length 128 \\\n",
    "                    --do_predict \\\n",
    "                    --do_eval \\\n",
    "                    --overwrite_output_dir \\\n",
    "                    --logging_steps 500 \\\n",
    "                    --save_steps 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run NER ITA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Model: \"/model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\"\n",
    "\n",
    "\n",
    "Dataset: conll2003_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./CharBERT/run_ner.py \\\n",
    "                    --data_dir \"./datasets/CoNLL2003_ita\" \\\n",
    "                    --model_type bert \\\n",
    "                    --model_name_or_path \"./model/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "                    --output_dir  \"./model/output/multilingual/NER_cased/conll2003_ita\" \\\n",
    "                    --num_train_epochs 3 \\\n",
    "                    --learning_rate 3e-5 \\\n",
    "                    --char_vocab \"./CharBERT/data/dict/bert_char_vocab\" \\\n",
    "                    --per_gpu_train_batch_size 6 \\\n",
    "                    --do_train \\\n",
    "                    --do_predict \\\n",
    "                    --overwrite_output_dir \\\n",
    "                    --save_steps 10000"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
